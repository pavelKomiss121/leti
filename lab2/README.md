# Лабораторная работа 2. Классификатор на основе логистической регрессии

**Цель:** разработка модели классификатора на основе логистической регрессии (scikit-learn), изучение свойств и принципов работы, оценка эффективности на разных типах данных.

---

## Как запустить

Из корня проекта `leti`:

```bash
pip install -r requirements.txt
python -m lab2.main
```

Скрипт выведет в консоль три таблицы (выборки А, Б, В) и сохранит 6 файлов гистограмм в текущую директорию.

---

## Откуда берутся данные

Используются функции из лабораторной работы 1 ([lab1/DataGenerator.py](../lab1/DataGenerator.py)):

- **norm_dataset(mu, sigma, N)** — два класса с нормальным распределением по признакам; параметры `mu` и `sigma` задают средние и СКО для каждого класса.
- **nonlinear_dataset_5(N)** — двумерные данные варианта 5 (вложенные области).

После генерации данные разбиваются в соотношении 70% обучающая / 30% тестовая (как в lab1).

---

## Что делает скрипт

1. **Выборка А** — хорошо разделимые нормальные данные (параметры как в lab1). Обучается логистическая регрессия с `solver='saga'` и `random_state=5`.
2. **Выборка Б** — нормальные данные с более близкими средними и большими СКО, классы сильнее пересекаются; ожидаемо хуже точность и метрики.
3. **Выборка В** — нелинейно разделимые данные из `nonlinear_dataset_5`; линейный классификатор (логистическая регрессия) даёт худшие результаты.

Для каждой выборки:

- **fit(Xtrain, Ytrain)** — обучение модели (подбор коэффициентов по обучающей выборке).
- **predict(X)** — предсказание метки класса (0 или 1) для объектов.
- **predict_proba(X)** — предсказание вероятностей принадлежности классу 0 и классу 1 (два столбца); для гистограмм используется столбец вероятности класса 1.

Далее считаются точность (доля верных ответов), чувствительность и специфичность (см. ниже), строятся гистограммы распределения вероятности класса 1 отдельно для объектов с истинной меткой 0 и с истинной меткой 1 (два цвета на одном графике).

---

## Чувствительность и специфичность (расчёт вручную)

- **Класс 0** — отсутствие признака, **класс 1** — наличие признака.
- **Чувствительность** = TP / (TP + FN) — среди всех истинных «положительных» (класс 1) доля верно предсказанных.
- **Специфичность** = TN / (TN + FP) — среди всех истинных «отрицательных» (класс 0) доля верно предсказанных.

TP, TN, FP, FN считаются по меткам предсказания (порог 0.5: вероятность класса 1 ≥ 0.5 → предсказание класс 1). В коде это реализовано в функции `sensitivity_specificity(Y_true, Y_pred)` без использования `sklearn.metrics`.

---

## Создаваемые файлы

| Файл | Описание |
|------|----------|
| `lab2_hist_test_A.png`, `lab2_hist_train_A.png` | Гистограммы вероятности класса 1 для выборки А (тест и трейн). |
| `lab2_hist_test_B.png`, `lab2_hist_train_B.png` | То же для выборки Б. |
| `lab2_hist_test_C.png`, `lab2_hist_train_C.png` | То же для выборки В. |

Таблицы с числом объектов, точностью (%), чувствительностью (%) и специфичностью (%) для Train и Test выводятся в консоль по каждой из трёх выборок — их можно перенести в отчёт.

Ответы на вопросы для самоконтроля — в файле **QUESTIONS_ANSWERS.md**.
