# Упражнение 5. Машинное обучение с библиотекой scikit-learn

## Краткая сводка (без кода)

**Цель.** Построить классификатор (логистическая регрессия), предсказывающий наличие диабета по таблице признаков: предобработка данных, разделение на X/Y и на train/test, обучение, оценка метрик, подбор параметра C.

**Предобработка.** Данные для sklearn — в виде NumPy-массивов (`df.values` или выборка столбцов). X — все признаки, Y — целевая переменная (class). Стандартизация: `preprocessing.scale(X)` — вычесть среднее и масштабировать по СКО. Категориальные признаки приводят к бинарным (one-hot) через `OneHotEncoder`: каждый категориальный столбец разбивается в несколько двоичных (0/1).

**Разделение выборки.** `train_test_split(X, Y, test_size=0.2, random_state=N)` — 80% train, 20% test; random_state фиксирует воспроизводимость.

**Обучение и предсказание.** `LogisticRegression(random_state=...).fit(X_train, Y_train)`, `model.predict(X_test)`.

**Метрики.** `accuracy_score(Y_test, Y_pred)` — доля верных ответов. Для бинарной классификации также подходят: F1 (`f1_score`), ROC-AUC (`roc_auc_score`), матрица ошибок (`confusion_matrix`).

**Улучшение модели.** Параметр регуляризации `C` в `LogisticRegression` (меньше C — сильнее регуляризация). Перебор по сетке `param_range = [100, 10, 1, 0.1, 0.01, 0.001]`; при желании — автоматизация через `GridSearchCV` и объединение шагов в `make_pipeline()`.

## Суть для защиты

- Зачем нужны стандартизация и one-hot для категорий при использовании логистической регрессии.
- Зачем делить данные на обучающую и тестовую выборки и что даёт фиксированный random_state.
- Интерпретация accuracy и одной дополнительной метрики (F1 или AUC); когда одной точности недостаточно (дисбаланс классов, разная цена ошибок).
