# Лабораторная работа 3. Деревья и леса решений

**Цель:** реализация классификаторов на основе дерева решений и случайного леса, сравнение их эффективности, построение ROC-кривых и подбор гиперпараметров.

---

## Как запустить

Из корня проекта `leti`:

```bash
pip install -r requirements.txt
python -m lab3.main
```

Скрипт выведет таблицы метрик по трём выборкам (А, Б, В) для дерева и леса, результаты подбора глубины дерева и числа деревьев в лесе, сохранит графики в текущую директорию.

---

## Откуда берутся данные

Используются генераторы из лабораторной работы 1 ([lab1/DataGenerator.py](../lab1/DataGenerator.py)):

- **Выборка А** — хорошо разделимые нормальные данные (как в lab1/lab2).
- **Выборка Б** — нормальные данные со средней степенью пересечения классов (близкие средние, большие СКО).
- **Выборка В** — нелинейно разделимые данные из `nonlinear_dataset_5`.

После генерации данные делятся 70% обучающая / 30% тестовая.

---

## Что делает скрипт

1. **Дерево решений (DecisionTreeClassifier)**  
   Обучается с `random_state=0` на каждой выборке. На обучающих данных точность часто близка к 1; на тестовых — ниже. Это типичное **переобучение**: дерево подстраивается под обучающую выборку (вплоть до запоминания объектов), поэтому на новых данных качество падает.

2. **Случайный лес (RandomForestClassifier)**  
   Ансамбль деревьев с `random_state=0`. Обычно даёт более стабильную тестовую точность и меньше переобучения за счёт усреднения многих деревьев, обученных на разных подвыборках и признаках.

3. **Метрики**  
   Для дерева и леса по каждой выборке считаются точность, чувствительность и специфичность (вручную по формулам TP/(TP+FN) и TN/(TN+FP)) на обучающей и тестовой подвыборках. Результаты выводятся в виде таблиц.

4. **ROC-кривые и AUC**  
   По тестовой выборке строятся ROC-кривые для дерева и леса на одном графике; площадь под кривой (AUC) считается через `sklearn.metrics.roc_auc_score`. Файлы: `lab3_roc_A.png`, `lab3_roc_B.png`, `lab3_roc_C.png`.

5. **Гистограммы вероятностей (только для леса)**  
   Распределение вероятности принадлежности классу 1 для объектов с истинной меткой 0 и 1 — отдельно для обучающей и тестовой выборок. Файлы: `lab3_hist_forest_train_A.png`, `lab3_hist_forest_test_A.png` (и аналогично B, C).

6. **Подбор гиперпараметров**  
   - **Глубина дерева (max_depth):** перебираются значения 3, 5, 10, 15 и без ограничения (None) на выборке Б; выводится точность на train и test. Ограничение глубины снижает переобучение.  
   - **Число деревьев в лесе (n_estimators):** перебор от 1 до 300 с шагом 10 на выборке А; выбирается значение с максимальным AUC на тестовой выборке.

---

## Создаваемые файлы

| Файл | Описание |
|------|----------|
| `lab3_roc_A.png`, `lab3_roc_B.png`, `lab3_roc_C.png` | ROC-кривые дерева и леса для выборок А, Б, В. |
| `lab3_roc_forest_only_*.png` | ROC только для леса (строится при установленном scikit-plot). |
| `lab3_hist_forest_train_A.png`, `lab3_hist_forest_test_A.png` | Гистограммы вероятностей леса по выборке А (трейн и тест). |
| Аналогично `*_B.png`, `*_C.png` | То же для выборок Б и В. |

Ответы на вопросы для самоконтроля — в **QUESTIONS_ANSWERS.md**.
